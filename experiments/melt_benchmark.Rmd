---
title: "Benchmarking computational efficiency of TreeSE methods"
author: "Giulio Benedetti and Leo Lahti"
date: "`r Sys.Date()`"
---

```{r source, include = FALSE}
source("data.R", local = knitr::knit_global())
```

```{r, echo = FALSE}
# test melting for tse
melt_tse_exec_time <- function(tse) {
  
  start.time1 <- Sys.time()
  molten_tse <- mia::meltAssay(tse,
                       add_row_data = TRUE,
                       add_col_data = TRUE)
  end.time1 <- Sys.time()
    
  return(end.time1 - start.time1)
  
}

# test melting for pseq
melt_pseq_exec_time <- function(pseq) {
      
  start.time2 <- Sys.time()
  molten_pseq <- phyloseq::psmelt(pseq)
  end.time2 <- Sys.time()
    
  return(end.time2 - start.time2)
      
}
```

```{r iteration, echo = FALSE, warning = FALSE}
for (tse in containers) {

  # define index and ranks of current data set
  cur_set <- which(lapply(containers, mainExpName) == mainExpName(tse))
  len_exp <- length(altExps(tse))
  
  # repeat experiment for each taxonomic rank
  for (rank in 1:len_exp) {
    
    # extract tse from list of containers
    alt_tse <- altExps(tse)[[rank]]
    
    # repeat experiment for each sample size
    for (N in sample_sizes) {
    
      # select data sets at least as large as sample_size
      if (ncol(alt_tse) >= N) {
      
        # define index of current sample size
        cur_N <- which(N == sample_sizes)
      
        # define df index to store results
        tse_ind <- cur_N + 2 * len_N * (rank - 1)
        pseq_ind <- cur_N + len_N + 2 * len_N * (rank - 1)
  
        # random subsetting
        subset_names <- sample(colnames(alt_tse), N)
        sub_tse <- alt_tse[ , colnames(alt_tse) %in% subset_names]
        sub_pseq <- makePhyloseqFromTreeSummarizedExperiment(sub_tse)

        # store dimensions
        df[[cur_set]]$Features[tse_ind] <- nrow(sub_tse)
        df[[cur_set]]$Features[pseq_ind] <- nrow(sub_tse)
        df[[cur_set]]$Samples[tse_ind] <- ncol(sub_tse)
        df[[cur_set]]$Samples[pseq_ind] <- ncol(sub_tse)

        # test melting for tse
        df[[cur_set]]$MeltTime[tse_ind] <- melt_tse_exec_time(sub_tse)

        # test melting for pseq
        df[[cur_set]]$MeltTime[pseq_ind] <- melt_pseq_exec_time(sub_pseq)
    
      }
    
    }
  
  }
  
}
```

```{r}
df <- merge_all(df)
```

```{r melting_features, echo = FALSE}
# Set breaks for log X scale
#m <- max(df$Features, na.rm=TRUE); r <- round(m, -(nchar(m)-1))
#v <- 10^seq(2, log10(r), by=1)
#v <- c(500, 1000, 2000, 5000, 10000)
v <- unique(na.omit(df$Features))

dfsub <- filter(df, Samples == 10, Rank == "Order")
p1 <- ggplot(dfsub, aes(x = Features, y = MeltTime, color = MeltCommand)) +
  geom_point() + 
  geom_line() +
  labs(title = paste("Melting comparison (N=", paste(unique(dfsub$Samples), collapse=","), ")", sep =""),
       x = "Features (D)",
       y = "Execution time (s)",
       color = "Method:",
       caption = "Execution time of melting as a function of number of features") +
  scale_x_log10(breaks=v, labels=v) + # Log is often useful with sample size
  # scale_y_log10() + # Log is often useful with sample size
  scale_color_manual(values=c("black", "darkgray")) + 
  theme(legend.position = "bottom")

print(p1)
```

# Compare execution time ratios

```{r melting_features_ratio, echo=FALSE, fig.width=10, fig.height=6}
df2 <- pivot_wider(dfsub[ , c("Dataset", "MeltTime", "Features", "ObjectType")] %>%
         filter(!is.na(MeltTime)), names_from=c(ObjectType),
	        values_from=MeltTime, Features) %>%
         mutate(Ratio=tse/pseq)

p2 <- ggplot(df2, aes(x=Features, y=Ratio)) +
        geom_point() +
        geom_line() +
	scale_y_continuous(labels=scales::percent) +
	geom_hline(aes(yintercept=1), linetype=2, color="gray") + 
	labs(title="Execution time ratio",
	     x="Features (N)",
	     y="Ratio (tse/pseq)")

print(p2)
```