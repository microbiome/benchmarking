---
title: "Benchmarking computational efficiency of TreeSE methods"
author: "Giulio Benedetti and Leo Lahti"
date: "`r Sys.Date()`"
---

```{r source, include = FALSE}
source("data.R", local = knitr::knit_global())
```

```{r dataframe, echo = FALSE}
# create NA data frame to store the execution times throughout the for loop
df <- df %>% mutate(Melt = rep(NA, 14 * len_set * len_N),
                    MeltCommand = rep(c(rep("mia::meltAssay", len_set * len_N), rep("phyloseq::psMelt", len_set * len_N)), 7))
```

```{r, echo = FALSE}
# test melting for tse
melt_tse_exec_time <- function(tse) {
  
  start.time1 <- Sys.time()
  molten_tse <- mia::meltAssay(tse,
                       add_row_data = TRUE,
                       add_col_data = TRUE)
  end.time1 <- Sys.time()
    
  return(end.time1 - start.time1)
  
}

# test melting for pseq
melt_pseq_exec_time <- function(pseq) {
      
  start.time2 <- Sys.time()
  molten_pseq <- phyloseq::psmelt(pseq)
  end.time2 <- Sys.time()
    
  return(end.time2 - start.time2)
      
}
```

```{r iteration, echo = FALSE, warning = FALSE}
for (data_set in data_sets) {

  # define index of current data set
  cur_set <- which(data_sets == data_set)
  
  # repeat experiment for each taxonomic rank
  for (rank in 1:7) {
    
    # extract tse and pseq from list of containers
    tse <- containers[[cur_set]][[rank]]
    
    # repeat experiment for each sample size
    for (N in sample_sizes) {
    
      # select data sets at least as large as sample_size
      if (ncol(tse) >= N) {
      
        # define index of current sample size
        cur_N <- which(N == sample_sizes)
      
        # define df index to store results
        tse_ind <- cur_set + len_set * (cur_N - 1) + 2 * len_set * len_N * (rank - 1)
        pseq_ind <- cur_set + len_set * (cur_N + len_N - 1) + 2 * len_set * len_N * (rank - 1)
  
        # random subsetting
        subset_names <- sample(colnames(tse), N)
        sub_tse <- tse[ , colnames(tse) %in% subset_names]
        sub_pseq <- makePhyloseqFromTreeSummarizedExperiment(sub_tse)

        # store dimensions
        df$Features[tse_ind] <- nrow(sub_tse)
        df$Features[pseq_ind] <- nrow(sub_tse)
        df$Samples[tse_ind] <- ncol(sub_tse)
        df$Samples[pseq_ind] <- ncol(sub_tse)

        # test melting for tse
        df$Melt[tse_ind] <- melt_tse_exec_time(sub_tse)

        # test melting for pseq
        df$Melt[pseq_ind] <- melt_pseq_exec_time(sub_pseq)
    
      }
    
    }
  
  }
  
}
```

```{r melting_features, echo = FALSE}
# 5) There is now lot of variation and no systematic trend; this may depend on data specifics;
#    could we get a similar table of running times within each data set? For instance, by
#    running melt for different taxonomic levels? Each taxonomic level has a different number
#    of features; the splitByRanks function gives abundance tables for all ranks

# Set breaks for log X scale
#m <- max(df$Features, na.rm=TRUE); r <- round(m, -(nchar(m)-1))
#v <- 10^seq(2, log10(r), by=1)
#v <- c(500, 1000, 2000, 5000, 10000)
v <- unique(na.omit(df$Features))

dfsub <- filter(df, Samples == 10, Rank == "Order")
p1 <- ggplot(dfsub, aes(x = Features, y = Melt, color = MeltCommand)) +
  geom_point() + 
  geom_line() +
  labs(title = paste("Melting comparison (N=", paste(unique(dfsub$Samples), collapse=","), ")", sep =""),
       x = "Features (D)",
       y = "Execution time (s)",
       color = "Method:",
       caption = "Execution time of melting as a function of number of features") +
  scale_x_log10(breaks=v, labels=v) + # Log is often useful with sample size
  # scale_y_log10() + # Log is often useful with sample size
  scale_color_manual(values=c("black", "darkgray")) + 
  theme(legend.position = "bottom")

print(p1)
```

# Compare execution time ratios

```{r melting_features_ratio, echo=FALSE, fig.width=10, fig.height=6}
df2 <- pivot_wider(dfsub[ , c("Dataset", "Melt", "Features", "ObjectType")] %>%
         filter(!is.na(Melt)), names_from=c(ObjectType),
	        values_from=Melt, Features) %>%
         mutate(Ratio=tse/pseq)

p2 <- ggplot(df2, aes(x=Features, y=Ratio)) +
        geom_point() +
        geom_line() +
	scale_y_continuous(labels=scales::percent) +
	geom_hline(aes(yintercept=1), linetype=2, color="gray") + 
	labs(title="Execution time ratio",
	     x="Features (N)",
	     y="Ratio (tse/pseq)")

print(p2)
```